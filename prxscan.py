import requests
import re
from collections import OrderedDict
import telebot
import argparse
import time

# C·∫•u h√¨nh Telegram
TELEGRAM_BOT_TOKEN = '7819235807:AAEpCtPhIAAjTJYz0Efho35YZVl6ikAxKtc'
TELEGRAM_CHAT_ID = '1243471275'

# C·∫•u h√¨nh regex v√† timeout
PROXY_PATTERN = re.compile(r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}:[0-9]{1,5}\b')
REQUEST_TIMEOUT = 20
TELEGRAM_TIMEOUT = 60

def send_file_to_telegram(file_path, caption=""):
    """G·ª≠i file qua Telegram v·ªõi timeout m·ªü r·ªông"""
    try:
        bot = telebot.TeleBot(TELEGRAM_BOT_TOKEN)
        with open(file_path, 'rb') as f:
            bot.send_document(
                chat_id=TELEGRAM_CHAT_ID,
                document=f,
                caption=caption[:1020] + '...' if len(caption) > 1024 else caption,
                timeout=TELEGRAM_TIMEOUT
            )
    except Exception as e:
        print(f"üî¥ L·ªói Telegram: {str(e)}")

def fetch_proxies(url):
    """L·∫•y danh s√°ch proxy t·ª´ URL v·ªõi x·ª≠ l√Ω l·ªói n√¢ng cao"""
    try:
        response = requests.get(
            url, 
            timeout=REQUEST_TIMEOUT,
            headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36'}
        )
        
        if response.status_code != 200:
            return f"üî¥ HTTP {response.status_code}", []
            
        proxies = PROXY_PATTERN.findall(response.text)
        return ("‚úÖ Th√†nh c√¥ng", proxies) if proxies else ("üö´ Kh√¥ng c√≥ proxy", [])

    except requests.exceptions.Timeout:
        return "‚è≥ Timeout", []
    except requests.exceptions.RequestException as e:
        return f"üî¥ K·∫øt n·ªëi: {str(e)}", []
    except Exception as e:
        return f"üî¥ L·ªói: {str(e)}", []

def process_urls(file_path):
    """X·ª≠ l√Ω danh s√°ch URL v√† ph√¢n lo·∫°i k·∫øt qu·∫£"""
    with open(file_path, 'r') as f:
        urls = [line.strip() for line in f if line.strip()]

    results = {
        'success': [],
        'failed': [],
        'proxies': [],
        'total_time': 0.0
    }

    for url in urls:
        print(f"\nüîé ƒêang qu√©t: {url}")
        start = time.time()
        status, proxies = fetch_proxies(url)
        elapsed = time.time() - start

        if proxies:
            results['success'].append(url)
            results['proxies'].extend(proxies)
            print(f"üü¢ {status} | {len(proxies)} proxy | ‚è±Ô∏è {elapsed:.2f}s")
        else:
            results['failed'].append((url, status))
            print(f"üî¥ {status} | ‚è±Ô∏è {elapsed:.2f}s")

        print("‚îÅ" * 60)
    
    return results

def update_url_lists(results):
    """C·∫≠p nh·∫≠t file URL v√† ghi log l·ªói"""
    # Ghi l·∫°i URL th√†nh c√¥ng
    with open(args.list, 'w') as f:
        f.write('\n'.join(results['success']))
    
    # Ghi log l·ªói chi ti·∫øt
    if results['failed']:
        with open('urlerror.txt', 'w') as f:
            f.write("\n".join([f"{url} | {error}" for url, error in results['failed']]))

def generate_report(results, exec_time):
    """T·∫°o b√°o c√°o ƒë·ªãnh d·∫°ng Markdown"""
    total_proxies = len(results['proxies'])
    unique_proxies = list(OrderedDict.fromkeys(results['proxies']))
    
    report = [
        "üì° **B√ÅO C√ÅO PROXY**",
        f"‚Ä¢ Proxy thu th·∫≠p: `{total_proxies}`",
        f"‚Ä¢ Proxy tr√πng l·∫∑p: `{total_proxies - len(unique_proxies)}`",
        f"‚Ä¢ Proxy h·ª£p l·ªá: `{len(unique_proxies)}`",
        f"‚Ä¢ URL th√†nh c√¥ng: `{len(results['success'])}`",
        f"‚Ä¢ URL th·∫•t b·∫°i: `{len(results['failed'])}`",
        f"\n‚è≥ Th·ªùi gian x·ª≠ l√Ω: `{exec_time:.2f}s`",
        f"üïí Chu k·ª≥ ti·∫øp theo sau: `5 ph√∫t`"
    ]
    
    if results['failed']:
        report.append("\nüî¥ **URL L·ªñI:**")
        report.extend([f"- `{url[:45]}...` | {error}" for url, error in results['failed'][:5]])
    
    return '\n'.join(report)

def main():
    global args
    parser = argparse.ArgumentParser(description="C√¥ng c·ª• qu√©t proxy th√¥ng minh")
    parser.add_argument('-l', '--list', required=True, help="File ch·ª©a danh s√°ch URL")
    args = parser.parse_args()

    while True:
        start_time = time.time()
        
        # Th·ª±c hi·ªán qu√©t
        results = process_urls(args.list)
        unique_proxies = list(OrderedDict.fromkeys(results['proxies']))
        
        # L∆∞u k·∫øt qu·∫£
        with open('live.txt', 'w') as f:
            f.write('\n'.join(unique_proxies))
        
        # C·∫≠p nh·∫≠t danh s√°ch
        update_url_lists(results)
        
        # T·∫°o v√† g·ª≠i b√°o c√°o
        exec_time = time.time() - start_time
        report = generate_report(results, exec_time)
        send_file_to_telegram('live.txt', report)
        
        print(f"\n‚è≥ T·ªïng th·ªùi gian: {exec_time:.2f}s")
        print(f"üïí B·∫Øt ƒë·∫ßu chu k·ª≥ m·ªõi sau 5 ph√∫t...\n{'‚ïê' * 50}")
        time.sleep(300)

if __name__ == "__main__":
    main()
